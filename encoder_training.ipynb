{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d834ea7d-1aa9-467b-9634-81543a2fc5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 512])\n"
     ]
    }
   ],
   "source": [
    "from encoder_layer import Encoder_block\n",
    "from positional_encoding import Positional_Encoding\n",
    "from datasets import load_from_disk\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d11b3a9-c073-4efc-b9c5-462a4b6cc33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(\"kp20k_local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62015f0a-6ffc-48d2-93dd-f6ee56bd33db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'document', 'doc_bio_tags', 'extractive_keyphrases', 'abstractive_keyphrases', 'other_metadata'],\n",
       "        num_rows: 530809\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'document', 'doc_bio_tags', 'extractive_keyphrases', 'abstractive_keyphrases', 'other_metadata'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'document', 'doc_bio_tags', 'extractive_keyphrases', 'abstractive_keyphrases', 'other_metadata'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c59e0643-7bbe-4259-8d70-cde762ede29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from training dataset split\n",
      "Fields in the sample:  ['id', 'document', 'doc_bio_tags', 'extractive_keyphrases', 'abstractive_keyphrases', 'other_metadata']\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample from training dataset split\")\n",
    "train_sample = dataset[\"train\"][0]\n",
    "print(\"Fields in the sample: \", [key for key in train_sample.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21f33221-6fcf-4859-b00f-5af9f451f62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Document:  ['virtually', 'enhancing', 'the', 'perception', 'of', 'user', 'actions', 'This', 'paper', 'proposes', 'using', 'virtual', 'reality', 'to', 'enhance', 'the', 'perception', 'of', 'actions', 'by', 'distant', 'users', 'on', 'a', 'shared', 'application.', 'Here,', 'distance', 'may', 'refer', 'either', 'to', 'space', '(', 'e.g.', 'in', 'a', 'remote', 'synchronous', 'collaboration)', 'or', 'time', '(', 'e.g.', 'during', 'playback', 'of', 'recorded', 'actions).', 'Our', 'approach', 'consists', 'in', 'immersing', 'the', 'application', 'in', 'a', 'virtual', 'inhabited', '3D', 'space', 'and', 'mimicking', 'user', 'actions', 'by', 'animating', 'avatars.', 'We', 'illustrate', 'this', 'approach', 'with', 'two', 'applications,', 'the', 'one', 'for', 'remote', 'collaboration', 'on', 'a', 'shared', 'application', 'and', 'the', 'other', 'to', 'playback', 'recorded', 'sequences', 'of', 'user', 'actions.', 'We', 'suggest', 'this', 'could', 'be', 'a', 'low', 'cost', 'enhancement', 'for', 'telepresence.']\n",
      "Document BIO Tags:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenized Document: \", train_sample[\"document\"])\n",
    "print(\"Document BIO Tags: \", train_sample[\"doc_bio_tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d1a3b31-6c4a-41b1-98c1-fbda8e3c7efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extractive/present Keyphrases:  ['telepresence', 'avatars']\n",
      "Abstractive/absent Keyphrases:  ['animation', 'application sharing', 'collaborative virtual environments']\n"
     ]
    }
   ],
   "source": [
    "print(\"Extractive/present Keyphrases: \", train_sample[\"extractive_keyphrases\"])\n",
    "print(\"Abstractive/absent Keyphrases: \", train_sample[\"abstractive_keyphrases\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3f82f44-d55e-4205-a6b2-53ca340fff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_tags = set()\n",
    "\n",
    "# for sample in dataset[\"train\"]:\n",
    "#     unique_tags.update(sample[\"doc_bio_tags\"])\n",
    "\n",
    "# print(\"Unique BIO Tags:\", unique_tags)\n",
    "# Unique BIO Tags: {'B', 'I', 'O'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f149223-ebbb-43c7-a6ed-674b477f7bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n-----------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25e37a5d-a3ac-4470-9876-05ced8f58b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from validation dataset split\n",
      "Fields in the sample:  ['id', 'document', 'doc_bio_tags', 'extractive_keyphrases', 'abstractive_keyphrases', 'other_metadata']\n"
     ]
    }
   ],
   "source": [
    "# sample from the validation split\n",
    "print(\"Sample from validation dataset split\")\n",
    "validation_sample = dataset[\"validation\"][0]\n",
    "print(\"Fields in the sample: \", [key for key in validation_sample.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc3a5539-ecab-4492-ab85-cb7521c45c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Document:  ['Real-Time', 'Data', 'Aggregation', 'in', 'Contention-Based', 'Wireless', 'Sensor', 'Networks', 'We', 'investigate', 'the', 'problem', 'of', 'delay', 'constrained', 'maximal', 'information', 'collection', 'for', 'CSMA-based', 'wireless', 'sensor', 'networks.', 'We', 'study', 'how', 'to', 'allocate', 'the', 'maximal', 'allowable', 'transmission', 'delay', 'at', 'each', 'node,', 'such', 'that', 'the', 'amount', 'of', 'information', 'collected', 'at', 'the', 'sink', 'is', 'maximized', 'and', 'the', 'total', 'delay', 'for', 'the', 'data', 'aggregation', 'is', 'within', 'the', 'given', 'bound.', 'We', 'formulate', 'the', 'problem', 'by', 'using', 'dynamic', 'programming', 'and', 'propose', 'an', 'optimal', 'algorithm', 'for', 'the', 'optimal', 'assignment', 'of', 'transmission', 'attempts.', 'Based', 'on', 'the', 'analysis', 'of', 'the', 'optimal', 'solution,', 'we', 'propose', 'a', 'distributed', 'greedy', 'algorithm.', 'It', 'is', 'shown', 'to', 'have', 'a', 'similar', 'performance', 'as', 'the', 'optimal', 'one.']\n",
      "Document BIO Tags:  ['O', 'B', 'I', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O']\n",
      "Extractive/present Keyphrases:  ['performance', 'sensor networks', 'data aggregation']\n",
      "Abstractive/absent Keyphrases:  ['algorithms', 'design', 'real-time traffic', 'csma/ca', 'delay constrained transmission']\n",
      "\n",
      "-----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenized Document: \", validation_sample[\"document\"])\n",
    "print(\"Document BIO Tags: \", validation_sample[\"doc_bio_tags\"])\n",
    "print(\"Extractive/present Keyphrases: \", validation_sample[\"extractive_keyphrases\"])\n",
    "print(\"Abstractive/absent Keyphrases: \", validation_sample[\"abstractive_keyphrases\"])\n",
    "print(\"\\n-----------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d5d879b-856f-4dfa-b74b-75b3149c1fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 530809\n",
      "Validation rows: 20000\n",
      "Test rows: 20000\n"
     ]
    }
   ],
   "source": [
    "print(\"Train rows:\", dataset[\"train\"].num_rows)\n",
    "print(\"Validation rows:\", dataset[\"validation\"].num_rows)\n",
    "print(\"Test rows:\", dataset[\"test\"].num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20889190-2004-4075-8660-ae91c33cb22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['id', 'document', 'doc_bio_tags', 'extractive_keyphrases', 'abstractive_keyphrases', 'other_metadata']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns:\", dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21f71892-58aa-4283-b2a6-abdfd2b005c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253.6750535964966 MB\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"].data.nbytes / (1024**2), \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4458593-f5cd-49f5-8166-1e3323f65a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1864f7e-d636-4030-b620-992f5c27aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f7ef4f-fec1-4572-9cc0-131e68f2bc95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f386a815-8c09-4889-9b8c-7486e51c2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_batch(batch):\n",
    "\n",
    "    # convert list of tokens to string\n",
    "    texts = [\" \".join(tokens) for tokens in batch[\"document\"]]\n",
    "    \n",
    "    tokenized = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "    # add word_ids manually (for each sample)\n",
    "    tokenized[\"word_ids\"] = [\n",
    "        tokenized.word_ids(i) for i in range(len(texts))\n",
    "    ]\n",
    "\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5221c6bb-d2e4-461d-acd3-6d59e28d8a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_tags_with_tokens(tags, word_ids):\n",
    "    new_tags = []\n",
    "    previous_word = None\n",
    "    \n",
    "    for word_id in word_ids:\n",
    "        if word_id is None:\n",
    "            new_tags.append(-100)\n",
    "        elif word_id >= len(tags):   # <-- IMPORTANT FIX\n",
    "            new_tags.append(-100)\n",
    "        else:\n",
    "            tag = tags[word_id]\n",
    "\n",
    "            # convert B → I for subwords\n",
    "            if word_id == previous_word and tag == 1:\n",
    "                tag = 2\n",
    "\n",
    "            new_tags.append(tag)\n",
    "\n",
    "        previous_word = word_id\n",
    "\n",
    "    return new_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "340de6b8-ac93-4fee-af67-5bf63b71ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_batch,\n",
    "    batched=True,\n",
    "    num_proc=1\n",
    ")\n",
    "\n",
    "tag2id = {\"O\": 0, \"B\": 1, \"I\": 2}\n",
    "\n",
    "def align_batch(batch):\n",
    "\n",
    "    aligned = []\n",
    "    \n",
    "    for tags, word_ids in zip(batch[\"doc_bio_tags\"], batch[\"word_ids\"]):\n",
    "\n",
    "        # convert \"O\",\"B\",\"I\" → 0,1,2\n",
    "        tags = [tag2id[t] for t in tags]\n",
    "\n",
    "        aligned_tags = align_tags_with_tokens(tags, word_ids)\n",
    "        aligned.append(aligned_tags)\n",
    "\n",
    "    batch[\"labels\"] = aligned\n",
    "    return batch\n",
    "\n",
    "tokenized_dataset = tokenized_dataset.map(\n",
    "    align_batch,\n",
    "    batched=True,\n",
    "    num_proc=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5d8f77f-806c-4982-8dd3-5ebf013c4107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(input_ids): 256\n",
      "len(labels): 256\n",
      "[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "sample = tokenized_dataset[\"train\"][0]\n",
    "\n",
    "print(\"len(input_ids):\", len(sample[\"input_ids\"]))\n",
    "print(\"len(labels):\", len(sample[\"labels\"]))\n",
    "print(sample[\"labels\"][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1c44e8f-f3c2-4bac-9130-7a7afc3505cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "833e997e-df53-4e0c-967b-84b788f8f5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'document', 'doc_bio_tags', 'extractive_keyphrases', 'abstractive_keyphrases', 'other_metadata', 'input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a348c161-9662-4561-aa3f-2fd1b829e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_loader:\n",
    "#     print(batch.keys())\n",
    "#     print(batch['input_ids'].shape)\n",
    "#     print(batch['attention_mask'].shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3344c804-0be0-425e-bb20-51ed547fd860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns and sample data types or values:\n",
      "id: type = <class 'NoneType'>, sample value = None\n",
      "document: type = <class 'list'>, sample value = ['virtually', 'enhancing', 'the', 'perception', 'of', 'user', 'actions', 'This', 'paper', 'proposes', 'using', 'virtual', 'reality', 'to', 'enhance', 'the', 'perception', 'of', 'actions', 'by', 'distant', 'users', 'on', 'a', 'shared', 'application.', 'Here,', 'distance', 'may', 'refer', 'either', 'to', 'space', '(', 'e.g.', 'in', 'a', 'remote', 'synchronous', 'collaboration)', 'or', 'time', '(', 'e.g.', 'during', 'playback', 'of', 'recorded', 'actions).', 'Our', 'approach', 'consists', 'in', 'immersing', 'the', 'application', 'in', 'a', 'virtual', 'inhabited', '3D', 'space', 'and', 'mimicking', 'user', 'actions', 'by', 'animating', 'avatars.', 'We', 'illustrate', 'this', 'approach', 'with', 'two', 'applications,', 'the', 'one', 'for', 'remote', 'collaboration', 'on', 'a', 'shared', 'application', 'and', 'the', 'other', 'to', 'playback', 'recorded', 'sequences', 'of', 'user', 'actions.', 'We', 'suggest', 'this', 'could', 'be', 'a', 'low', 'cost', 'enhancement', 'for', 'telepresence.']\n",
      "doc_bio_tags: type = <class 'list'>, sample value = ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B']\n",
      "extractive_keyphrases: type = <class 'list'>, sample value = ['telepresence', 'avatars']\n",
      "abstractive_keyphrases: type = <class 'list'>, sample value = ['animation', 'application sharing', 'collaborative virtual environments']\n",
      "other_metadata: type = <class 'dict'>, sample value = {'text': [], 'bio_tags': []}\n",
      "input_ids: type = <class 'list'>, sample value = [101, 8990, 20226, 1996, 10617, 1997, 5310, 4506, 2023, 3259, 17146, 2478, 7484, 4507, 2000, 11598, 1996, 10617, 1997, 4506, 2011, 6802, 5198, 2006, 1037, 4207, 4646, 1012, 2182, 1010, 3292, 2089, 6523, 2593, 2000, 2686, 1006, 1041, 1012, 1043, 1012, 1999, 1037, 6556, 26351, 8093, 17175, 2271, 5792, 1007, 2030, 2051, 1006, 1041, 1012, 1043, 1012, 2076, 18245, 1997, 2680, 4506, 1007, 1012, 2256, 3921, 3774, 1999, 10047, 16862, 2075, 1996, 4646, 1999, 1037, 7484, 9613, 7605, 2686, 1998, 23150, 6834, 5310, 4506, 2011, 2019, 22835, 22128, 2015, 1012, 2057, 19141, 2023, 3921, 2007, 2048, 5097, 1010, 1996, 2028, 2005, 6556, 5792, 2006, 1037, 4207, 4646, 1998, 1996, 2060, 2000, 18245, 2680, 10071, 1997, 5310, 4506, 1012, 2057, 6592, 2023, 2071, 2022, 1037, 2659, 3465, 22415, 2005, 10093, 13699, 6072, 10127, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "token_type_ids: type = <class 'list'>, sample value = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_mask: type = <class 'list'>, sample value = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "word_ids: type = <class 'list'>, sample value = [None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 43, 43, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 64, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 74, 75, 76, 77, 78, 78, 79, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 119, 119, 119, 120, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "labels: type = <class 'list'>, sample value = [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n"
     ]
    }
   ],
   "source": [
    "sample = tokenized_dataset[\"train\"][0]  # first example\n",
    "\n",
    "print(\"Columns and sample data types or values:\")\n",
    "for col in sample.keys():\n",
    "    print(f\"{col}: type = {type(sample[col])}, sample value = {sample[col]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3140585b-440b-4f0a-a161-8274845ace4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"]\n",
    "\n",
    "tokenized_dataset_new = tokenized_dataset.remove_columns(\n",
    "    [col for col in tokenized_dataset[\"train\"].column_names if col not in columns_to_keep]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26a7d087-9790-4703-b255-1e7da7eb37ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 530809\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "219efb4c-b0b0-4cd0-a0b2-201a8038b96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_dataset_new[\"train\"][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3485846b-bae6-4f73-bb46-02766081a7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_sample = dataset[\"validation\"][0]\n",
    "len(validation_sample[\"doc_bio_tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "982ba9ef-3d78-42fa-8732-5cc9bb307787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(tokenized_dataset_new[\"train\"][0][\"doc_bio_tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67c066f1-0546-4b7e-8e90-63f88ab8e22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_dataset[\"train\"][0][\"doc_bio_tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b65f114-c5d8-45fb-b95b-3468cc3c557b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_dataset_new[\"train\"][0][\"token_type_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f65503c7-d82d-458a-b6fd-851fd8fa0ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_dataset_new[\"train\"][0][\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae6c12aa-1ddd-4bc5-bc2f-e40ecf57ee49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'document', 'doc_bio_tags', 'extractive_keyphrases', 'abstractive_keyphrases', 'other_metadata', 'input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "    num_rows: 530809\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0583f698-4cfb-4d0c-9cc7-88cc2c96cf13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "530809"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4efcd0fb-3a95-435b-8eba-899f856a8c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = tokenized_dataset[\"train\"][0]\n",
    "len(example[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdc7e37e-3e06-42c6-ab9d-8e1b2a157d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 8990,\n",
       " 20226,\n",
       " 1996,\n",
       " 10617,\n",
       " 1997,\n",
       " 5310,\n",
       " 4506,\n",
       " 2023,\n",
       " 3259,\n",
       " 17146,\n",
       " 2478,\n",
       " 7484,\n",
       " 4507,\n",
       " 2000,\n",
       " 11598,\n",
       " 1996,\n",
       " 10617,\n",
       " 1997,\n",
       " 4506,\n",
       " 2011,\n",
       " 6802,\n",
       " 5198,\n",
       " 2006,\n",
       " 1037,\n",
       " 4207,\n",
       " 4646,\n",
       " 1012,\n",
       " 2182,\n",
       " 1010,\n",
       " 3292,\n",
       " 2089,\n",
       " 6523,\n",
       " 2593,\n",
       " 2000,\n",
       " 2686,\n",
       " 1006,\n",
       " 1041,\n",
       " 1012,\n",
       " 1043,\n",
       " 1012,\n",
       " 1999,\n",
       " 1037,\n",
       " 6556,\n",
       " 26351,\n",
       " 8093,\n",
       " 17175,\n",
       " 2271,\n",
       " 5792,\n",
       " 1007,\n",
       " 2030,\n",
       " 2051,\n",
       " 1006,\n",
       " 1041,\n",
       " 1012,\n",
       " 1043,\n",
       " 1012,\n",
       " 2076,\n",
       " 18245,\n",
       " 1997,\n",
       " 2680,\n",
       " 4506,\n",
       " 1007,\n",
       " 1012,\n",
       " 2256,\n",
       " 3921,\n",
       " 3774,\n",
       " 1999,\n",
       " 10047,\n",
       " 16862,\n",
       " 2075,\n",
       " 1996,\n",
       " 4646,\n",
       " 1999,\n",
       " 1037,\n",
       " 7484,\n",
       " 9613,\n",
       " 7605,\n",
       " 2686,\n",
       " 1998,\n",
       " 23150,\n",
       " 6834,\n",
       " 5310,\n",
       " 4506,\n",
       " 2011,\n",
       " 2019,\n",
       " 22835,\n",
       " 22128,\n",
       " 2015,\n",
       " 1012,\n",
       " 2057,\n",
       " 19141,\n",
       " 2023,\n",
       " 3921,\n",
       " 2007,\n",
       " 2048,\n",
       " 5097,\n",
       " 1010,\n",
       " 1996,\n",
       " 2028,\n",
       " 2005,\n",
       " 6556,\n",
       " 5792,\n",
       " 2006,\n",
       " 1037,\n",
       " 4207,\n",
       " 4646,\n",
       " 1998,\n",
       " 1996,\n",
       " 2060,\n",
       " 2000,\n",
       " 18245,\n",
       " 2680,\n",
       " 10071,\n",
       " 1997,\n",
       " 5310,\n",
       " 4506,\n",
       " 1012,\n",
       " 2057,\n",
       " 6592,\n",
       " 2023,\n",
       " 2071,\n",
       " 2022,\n",
       " 1037,\n",
       " 2659,\n",
       " 3465,\n",
       " 22415,\n",
       " 2005,\n",
       " 10093,\n",
       " 13699,\n",
       " 6072,\n",
       " 10127,\n",
       " 1012,\n",
       " 102,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"train\"][0][\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa2841bc-7d8d-4fe9-a612-b174d08d0843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(tokens, words, encoder, prepare_encoder_input, top_k=2):\n",
    "    \"\"\"\n",
    "    tokens: list of token ids (ints)\n",
    "    words: list of corresponding words (strings)\n",
    "    encoder: your Encoder_block object (already initialized)\n",
    "    prepare_encoder_input: function jo tokens ko encoder input me convert karta hai\n",
    "    top_k: kitne keywords chahiye\n",
    "    \n",
    "    Returns:\n",
    "        keywords: list of top-k keywords extracted using attention weights\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Prepare input tensor for encoder\n",
    "    x = prepare_encoder_input(tokens)  # assume ye function tensor return karta hai\n",
    "    \n",
    "    # Step 2: Forward pass through encoder\n",
    "    output, attn = encoder(x)\n",
    "    \n",
    "    # Step 3: Average attention weights across heads\n",
    "    attn_avg = attn.mean(dim=0)   # shape: (seq_len, seq_len)\n",
    "    \n",
    "    # Step 4: Take attention for CLS token or first token (index 0)\n",
    "    attn_avg = attn_avg[0]        # shape: (seq_len,)\n",
    "    \n",
    "    # Step 5: Average attention across source positions to get word importance\n",
    "    word_importance = attn_avg.mean(dim=0)  # shape: (seq_len,)\n",
    "    \n",
    "    # Step 6: Pick top-k words with highest importance\n",
    "    values, indices = torch.topk(word_importance, k=top_k)\n",
    "    indices = indices.tolist()\n",
    "    \n",
    "    # Step 7: Convert indices to actual words\n",
    "    keywords = [words[i] for i in indices]\n",
    "    \n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d126e886-0155-4109-8bfb-43a896e3b343",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512  # main model dimension\n",
    "num_heads = 8  # number of heads\n",
    "d_ff = 2048    # feedforward hidden dimension\n",
    "seq_len = 128  # max input length\n",
    "vocab_size = 30000\n",
    "embedding_layer = nn.Embedding(vocab_size, d_model)\n",
    "encoder_layer = Encoder_block(d_model=512, d_ff=2048, num_heads=8)\n",
    "pos_encoding = Positional_Encoding(seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0786331d-6d6a-44ed-8ef9-aba05e6f0687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def prepare_encoder_input(token_ids):\n",
    "    token_ids = torch.tensor(token_ids).unsqueeze(0)  # (1, seq_len)\n",
    "\n",
    "    # 1. Convert token IDs → learned embeddings\n",
    "    x = embedding_layer(token_ids)                      # (1, seq_len, d_model)\n",
    "\n",
    "    # 2. Add sinusoidal positional encoding\n",
    "    x = pos_encoding(x)                                 # (1, seq_len, d_model)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5fe6a85-60d7-4472-8d8f-5152a572ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_tensor = prepare_encoder_input(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ea5db94-117d-44e4-bdf6-1e3fc682e0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted keywords: ['I', 'love']\n"
     ]
    }
   ],
   "source": [
    "tokens = [1542, 1542, 1542]  # \"I love you\"\n",
    "words = [\"I\", \"love\", \"you\"]\n",
    "\n",
    "encoder_layer = Encoder_block(d_model=512, d_ff=2048, num_heads=8)\n",
    "# prepare_encoder_input() tumhara input prepare karne wala function hai\n",
    "\n",
    "keywords = extract_keywords(tokens, words, encoder_layer, prepare_encoder_input, top_k=2)\n",
    "print(\"Extracted keywords:\", keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55a50649-6545-46eb-842e-cf715d5919ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0eac8b68-6b37-404c-ac28-c59688577ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    # 1. Let HF collator pad input_ids, attention_mask, etc.\n",
    "    batch_encoded = data_collator(batch)\n",
    "\n",
    "    # 2. Pad labels to max batch length\n",
    "    max_len = batch_encoded[\"input_ids\"].shape[1]\n",
    "\n",
    "    padded_labels = []\n",
    "    for item in batch:\n",
    "        labels = item[\"labels\"]\n",
    "        # pad using -100 → ignored in loss\n",
    "        padded = labels + [-100] * (max_len - len(labels))\n",
    "        padded_labels.append(padded)\n",
    "\n",
    "    batch_encoded[\"labels\"] = torch.tensor(padded_labels)\n",
    "\n",
    "    return batch_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cb762096-0cdd-40bd-9bf8-fba65ee72cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(\n",
    "#     tokenized_dataset_new[\"train\"],\n",
    "#     batch_size=8,\n",
    "#     shuffle=True,\n",
    "#     collate_fn=data_collator,\n",
    "# )\n",
    "train_loader = DataLoader(\n",
    "    tokenized_dataset_new[\"train\"],\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    num_workers=4  # adjust based on your CPU cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e9201e72-a95a-4a35-9157-f42ed2d3bb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x20e2dfe7980>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "719e88d1-8755-4a8b-951b-ba72af156024",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = Encoder_block(d_model=512, d_ff=2048, num_heads=8)\n",
    "model = model.to(device)  # agar GPU hai to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a5a1ebf-bf16-4785-8e55-4f69d0e15d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "num_classes = 3  # B, I, O\n",
    "# Define classifier on top of encoder output\n",
    "classifier = nn.Linear(d_model, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8a152365-46c9-4cc9-afc5-fbe1abb7fb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder_block(\n",
       "  (ffn): feedforward(\n",
       "    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (multi_att): MultiHeadAttention(\n",
       "    (Q): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (K): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (V): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (fc_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (norm_layer1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (norm_layer2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6c823d6a-179f-46b1-a38b-5c3cf99d55a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.tensor([0.1, 1.0, 1.2]).to(device)   # O, B, I\n",
    "criterion  = nn.CrossEntropyLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fef33f03-3206-48b8-9bb7-e26afe87da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "# Optimizer over both encoder and classifier params\n",
    "optimizer = torch.optim.AdamW(list(model.parameters()) + list(classifier.parameters()), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639e153c-d5b7-4b71-8a6a-242f5eeb922f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4144cd08-6c0d-4512-a056-4917129af483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_loader:\n",
    "#     print(batch.keys())  # Batch ke andar available keys dikha dega\n",
    "    \n",
    "#     if 'input_ids' in batch:\n",
    "#         print(\"input_ids present\")\n",
    "#     else:\n",
    "#         print(\"input_ids NOT present\")\n",
    "        \n",
    "#     if 'attention_mask' in batch:\n",
    "#         print(\"attention_mask present\")\n",
    "#     else:\n",
    "#         print(\"attention_mask NOT present\")\n",
    "    \n",
    "#     # Bas pehla batch hi check karna hai toh loop break kar do\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1c438a39-5584-4a2f-98fd-66e4c2776956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_loader:\n",
    "#     for k, v in batch.items():\n",
    "#         print(k, type(v))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "996c1b52-5873-4387-9ef9-c7e89994fceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512  # main model dimension\n",
    "num_heads = 8  # number of heads\n",
    "d_ff = 2048    # feedforward hidden dimension\n",
    "seq_len = 256  # max input length\n",
    "vocab_size = 30000\n",
    "embedding_layer = nn.Embedding(vocab_size, d_model).to(device)\n",
    "encoder_layer = Encoder_block(d_model=512, d_ff=2048, num_heads=8).to(device)\n",
    "pos_encoding = Positional_Encoding(seq_len, d_model).to(device)\n",
    "\n",
    "def prepare_batch_encoder_input(input_ids):\n",
    "    # input_ids = (batch_size, seq_len) already tensor\n",
    "    x = embedding_layer(input_ids)      # (batch, seq_len, d_model)\n",
    "    x = pos_encoding(x)                 # (batch, seq_len, d_model)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4617f61e-8bdb-475e-bf54-e6fc90913c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'document', 'doc_bio_tags', 'extractive_keyphrases', 'abstractive_keyphrases', 'other_metadata', 'input_ids', 'token_type_ids', 'attention_mask', 'word_ids', 'labels']\n",
      "['input_ids', 'token_type_ids', 'attention_mask', 'labels']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset[\"train\"].column_names)\n",
    "print(tokenized_dataset_new[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d19b0a2e-dd6e-49c5-bd43-7d7d6ccd9ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# num_epochs = 5\n",
    "\n",
    "# model.train()\n",
    "# classifier.train()\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     total_loss = 0\n",
    "    \n",
    "#     # tqdm wrapper for train_loader with a description\n",
    "#     loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "#     for batch in loop:\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         labels = batch['labels'].to(device)  # (B, L)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         x = prepare_batch_encoder_input(input_ids)  # (B, L, d_model)\n",
    "        \n",
    "#         encoder_output, attn_weights = model(x, mask=None)  # (B, L, d_model)\n",
    "        \n",
    "#         logits = classifier(encoder_output)  # (B, L, 3)\n",
    "        \n",
    "#         loss = criterion(\n",
    "#             logits.view(-1, 3),  # (B*L, 3)\n",
    "#             labels.view(-1)      # (B*L)\n",
    "#         )\n",
    "        \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#         # Update tqdm postfix to show loss dynamically\n",
    "#         loop.set_postfix(loss=total_loss / (loop.n + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a2b90b42-f277-40f2-b370-1a5ba770daea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|█████████████████████████████████████████████████████| 66352/66352 [28:30<00:00, 38.79it/s, loss=0.779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] completed. Average Loss: 0.7794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|█████████████████████████████████████████████████████| 66352/66352 [28:52<00:00, 38.31it/s, loss=0.737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5] completed. Average Loss: 0.7370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████████████████████████████████████████████████| 66352/66352 [28:22<00:00, 38.98it/s, loss=0.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5] completed. Average Loss: 0.7202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████████████████████████████████████████████████| 66352/66352 [28:23<00:00, 38.94it/s, loss=0.71]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5] completed. Average Loss: 0.7098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|█████████████████████████████████████████████████████| 66352/66352 [28:16<00:00, 39.10it/s, loss=0.702]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5] completed. Average Loss: 0.7019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create a logs directory if it doesn't exist\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='logs/training.log', \n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "model.train()\n",
    "classifier.train()\n",
    "\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    for batch in loop:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)  # (B, L)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = prepare_batch_encoder_input(input_ids)  # (B, L, d_model)\n",
    "\n",
    "        encoder_output, attn_weights = model(x, mask=None)  # (B, L, d_model)\n",
    "\n",
    "        logits = classifier(encoder_output)  # (B, L, 3)\n",
    "\n",
    "        loss = criterion(\n",
    "            logits.view(-1, 3),  # (B*L, 3)\n",
    "            labels.view(-1)      # (B*L)\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=total_loss / (loop.n + 1))\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    # Logging average loss after each epoch\n",
    "    logging.info(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] completed. Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Save checkpoint after each epoch\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch+1}.pt\")\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'classifier_state_dict': classifier.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': avg_loss,\n",
    "    }, checkpoint_path)\n",
    "    \n",
    "    logging.info(f\"Checkpoint saved at {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614f57b2-45e9-4ff8-a19d-88bb7a73807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[\"train\"][0][\"document\"])\n",
    "print(type(dataset[\"train\"][0][\"document\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3006bd-0bbd-45d0-9fbb-0933e9df1d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b639975e-c6d2-46f8-a272-045a0bbf842f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2efcf51c-e75e-42ce-9ff0-b02082059764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d25c128-3c0d-4561-9259-50597e1a75df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5be78a-1625-44d2-a0e7-2adb256e7ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1474821-1af8-42d5-b868-118cf49e2c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87d6899-8ec5-4b65-8cdf-ebe1385028f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf036300-0fee-4af1-b956-a56c5b3deaa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f80cc0b-a22e-4b27-a9e9-ca381ca0634b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 512])\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b6e391b-a041-414d-9ca2-6973d11612be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_words(input_ids):\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0].tolist())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c32e190c-f868-46f1-9825-4e83a9654fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_better(input_ids, attn_weights, top_k=5):\n",
    "    \n",
    "    # CASE 1 — attn_weights is a list of tensors (layers × heads)\n",
    "    if isinstance(attn_weights, list):\n",
    "        attn_stack = torch.stack(attn_weights)   # (L, H, S, S)\n",
    "        cls_scores = attn_stack[:, :, 0, :].mean(dim=(0, 1))  # avg layers+heads\n",
    "    \n",
    "    # CASE 2 — attn_weights is a single tensor (heads × S × S)\n",
    "    else:\n",
    "        # attn_weights = (H, S, S)\n",
    "        cls_scores = attn_weights[:, 0, :].mean(dim=0)  # avg heads\n",
    "\n",
    "    # Remove CLS token (index 0)\n",
    "    token_scores = cls_scores[1:]  # first token is CLS\n",
    "\n",
    "    # Get top tokens\n",
    "    top_indices = torch.topk(token_scores, top_k).indices\n",
    "\n",
    "    # Get wordpiece IDs → convert to tokens\n",
    "    top_token_ids = input_ids[0][1:][top_indices]   # skip CLS\n",
    "    \n",
    "    top_tokens = tokenizer.convert_ids_to_tokens(top_token_ids.tolist())\n",
    "    return top_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dfacc65d-4d76-460f-b16b-8a8d557caa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Keywords: ['are', 'transformers', '.', 'amazing']\n"
     ]
    }
   ],
   "source": [
    "encoder_output, attn_weights, input_ids = encode_text(\"Transformers are amazing.\")\n",
    "\n",
    "keywords = extract_keywords(input_ids, attn_weights, top_k=4)\n",
    "\n",
    "print(\"Extracted Keywords:\", keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ad3e92b0-4f54-4368-a18b-cea35b8f1765",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = {\"is\", \"are\", \"the\", \"a\", \"an\", \"of\", \"to\", \"and\"}\n",
    "\n",
    "def filter_keywords(words):\n",
    "    return [w for w in words if w.lower() not in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4cacf7ce-cf9e-4f84-95fc-aaaafb136b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transformers', '.', 'amazing']\n"
     ]
    }
   ],
   "source": [
    "keywords = extract_keywords(input_ids, attn_weights, top_k=4)\n",
    "# keywords = merge_subwords(keywords)\n",
    "keywords = filter_keywords(keywords)[:5]  # pick top 2 after filtering\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "894927d5-607b-4542-861c-2f71e0593f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"averaged_perceptron_tagger_eng\")\n",
    "\n",
    "from nltk import pos_tag\n",
    "\n",
    "def prefer_nouns_adjectives(words):\n",
    "    tags = pos_tag(words, tagset=\"universal\")  # works in new NLTK\n",
    "    ranked = sorted(tags, key=lambda x: 0 if x[1] in (\"NOUN\",\"ADJ\") else 1)\n",
    "    return [w for w, t in ranked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ba27603-5319-482a-bf19-f931ede2f573",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m keywords \u001b[38;5;241m=\u001b[39m \u001b[43mextract_keywords_better\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m keywords \u001b[38;5;241m=\u001b[39m merge_subwords(keywords)\n\u001b[0;32m      3\u001b[0m keywords \u001b[38;5;241m=\u001b[39m filter_stopwords(keywords)\n",
      "Cell \u001b[1;32mIn[54], line 22\u001b[0m, in \u001b[0;36mextract_keywords_better\u001b[1;34m(input_ids, attn_weights, top_k)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Get wordpiece IDs → convert to tokens\u001b[39;00m\n\u001b[0;32m     20\u001b[0m top_token_ids \u001b[38;5;241m=\u001b[39m input_ids[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m:][top_indices]   \u001b[38;5;66;03m# skip CLS\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m top_tokens \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mconvert_ids_to_tokens(\u001b[43mtop_token_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m top_tokens\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "keywords = extract_keywords_better(input_ids, attn_weights, top_k=10)\n",
    "keywords = merge_subwords(keywords)\n",
    "keywords = filter_stopwords(keywords)\n",
    "keywords[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "13f0541c-3a02-401c-a134-3b52f24c1033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_better(input_ids, attn_weights, top_k=3):\n",
    "    # attn_weights = [num_layers, num_heads, seq, seq]\n",
    "    attn_stack = torch.stack(attn_weights)         # combine layers\n",
    "    cls_scores = attn_stack[:, :, 0, :].mean(dim=(0,1))  # avg across layers + heads\n",
    "    \n",
    "    token_ids = input_ids[0][1:]                # skip CLS\n",
    "    cls_scores = cls_scores[1:]                 # skip CLS\n",
    "\n",
    "    topk = torch.topk(cls_scores, k=top_k)\n",
    "    keywords = [tokenizer.convert_ids_to_tokens(token_ids[i].item())\n",
    "                for i in topk.indices.tolist()]\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea20f17c-a455-4330-8e7d-c973241a3766",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m keywords \u001b[38;5;241m=\u001b[39m \u001b[43mextract_keywords_better\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m keywords \u001b[38;5;241m=\u001b[39m merge_subwords(keywords)\n\u001b[0;32m      3\u001b[0m keywords \u001b[38;5;241m=\u001b[39m filter_stopwords(keywords)\n",
      "Cell \u001b[1;32mIn[48], line 3\u001b[0m, in \u001b[0;36mextract_keywords_better\u001b[1;34m(input_ids, attn_weights, top_k)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_keywords_better\u001b[39m(input_ids, attn_weights, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# attn_weights = [num_layers, num_heads, seq, seq]\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     attn_stack \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m)\u001b[49m         \u001b[38;5;66;03m# combine layers\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     cls_scores \u001b[38;5;241m=\u001b[39m attn_stack[:, :, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# avg across layers + heads\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     token_ids \u001b[38;5;241m=\u001b[39m input_ids[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m:]                \u001b[38;5;66;03m# skip CLS\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor"
     ]
    }
   ],
   "source": [
    "keywords = extract_keywords_better(input_ids, attn_weights, top_k=10)\n",
    "keywords = merge_subwords(keywords)\n",
    "keywords = filter_stopwords(keywords)\n",
    "keywords = keywords[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a5854b-c57e-4580-882d-1ee3e4f51b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

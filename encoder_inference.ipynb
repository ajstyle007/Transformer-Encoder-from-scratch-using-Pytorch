{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed9bf444-3a52-4eb2-87f1-74202c3fe75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 512])\n"
     ]
    }
   ],
   "source": [
    "from encoder_layer import Encoder_block\n",
    "from positional_encoding import Positional_Encoding\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91ffb7d7-463b-4ab4-8f81-4a9cf6583d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "449a7222-3867-4bd4-bfbe-0a6b897063f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from epoch: 5\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ckpt = torch.load(\"checkpoints/checkpoint_epoch_5.pt\", map_location=device)\n",
    "\n",
    "# recreate model\n",
    "encoder = Encoder_block(d_model=512, d_ff=2048, num_heads=8).to(device)\n",
    "d_model = 512\n",
    "num_classes = 3  # B, I, O\n",
    "# Define classifier on top of encoder output\n",
    "classifier = nn.Linear(d_model, num_classes).to(device)  # 3 = BIO tags\n",
    "\n",
    "encoder.load_state_dict(ckpt['model_state_dict'])\n",
    "classifier.load_state_dict(ckpt['classifier_state_dict'])\n",
    "\n",
    "encoder.eval()\n",
    "classifier.eval()\n",
    "\n",
    "print(\"Loaded checkpoint from epoch:\", ckpt['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c12e0a-a40a-40ae-b46c-168ba981edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512  # main model dimension\n",
    "num_heads = 8  # number of heads\n",
    "d_ff = 2048    # feedforward hidden dimension\n",
    "seq_len = 256  # max input length\n",
    "vocab_size = 30000\n",
    "embedding_layer = nn.Embedding(vocab_size, d_model).to(device)\n",
    "encoder_layer = Encoder_block(d_model=512, d_ff=2048, num_heads=8).to(device)\n",
    "pos_encoding = Positional_Encoding(seq_len, d_model).to(device)\n",
    "\n",
    "def prepare_batch_encoder_input(input_ids):\n",
    "    # input_ids = (batch_size, seq_len) already tensor\n",
    "    x = embedding_layer(input_ids)      # (batch, seq_len, d_model)\n",
    "    x = pos_encoding(x)                 # (batch, seq_len, d_model)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e3b18f-9906-4bd7-8435-eca3524c3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_batch(batch):\n",
    "\n",
    "    # convert list of tokens to string\n",
    "    texts = [\" \".join(tokens) for tokens in batch[\"document\"]]\n",
    "    \n",
    "    tokenized = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "    # add word_ids manually (for each sample)\n",
    "    tokenized[\"word_ids\"] = [\n",
    "        tokenized.word_ids(i) for i in range(len(texts))\n",
    "    ]\n",
    "\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab0a032d-56a4-4cad-b2b7-67acf1657abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(text):\n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "    input_ids = encoded[\"input_ids\"].to(device)\n",
    "\n",
    "    # Step 1: convert input_ids → embeddings\n",
    "    x = embedding_layer(input_ids)\n",
    "    x = pos_encoding(x)\n",
    "\n",
    "    # Step 2: pass through trained encoder\n",
    "    with torch.no_grad():\n",
    "        encoder_output, attn_weights = encoder(x, mask=None)\n",
    "\n",
    "    return encoder_output, attn_weights, input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05841130-29b5-41eb-bc46-79b283334ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, attention, input_ids = encode_text(\"Transformers are amazing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2f25451-e918-4d32-a47a-4e024a866330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 512])\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "295dd970-9024-49c8-b231-dbb0cbbfe5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_words(input_ids):\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0].tolist())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00638366-757b-4978-94cf-8c070b996ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_better(input_ids, attn_weights, top_k=5):\n",
    "    \n",
    "    # CASE 1 — attn_weights is a list of tensors (layers × heads)\n",
    "    if isinstance(attn_weights, list):\n",
    "        attn_stack = torch.stack(attn_weights)   # (L, H, S, S)\n",
    "        cls_scores = attn_stack[:, :, 0, :].mean(dim=(0, 1))  # avg layers+heads\n",
    "    \n",
    "    # CASE 2 — attn_weights is a single tensor (heads × S × S)\n",
    "    else:\n",
    "        # attn_weights = (H, S, S)\n",
    "        cls_scores = attn_weights[:, 0, :].mean(dim=0)  # avg heads\n",
    "\n",
    "    # Remove CLS token (index 0)\n",
    "    token_scores = cls_scores[1:]  # first token is CLS\n",
    "\n",
    "    # Get top tokens\n",
    "    top_indices = torch.topk(token_scores, top_k).indices\n",
    "\n",
    "    # Get wordpiece IDs → convert to tokens\n",
    "    top_token_ids = input_ids[0][1:][top_indices]   # skip CLS\n",
    "    \n",
    "    top_tokens = tokenizer.convert_ids_to_tokens(top_token_ids.tolist())\n",
    "    return top_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aa2aaa-4a58-4a3f-988f-5903ccdf87c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74776363-9b3c-4f80-bf8b-72d98ea19dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f809991-3498-475d-839f-05a398772bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Keywords: ['are', 'transformers', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "encoder_output, attn_weights, input_ids = encode_text(\"Transformers are amazing.\")\n",
    "attn_weights = attn_weights.squeeze(0)\n",
    "\n",
    "keywords = extract_keywords_better(input_ids, attn_weights, top_k=4)\n",
    "\n",
    "print(\"Extracted Keywords:\", keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d23d4ca-eed4-4e44-8067-ed69e63e4ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 256])\n",
      "attn_weights shape: torch.Size([8, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"input_ids shape:\", input_ids.shape)\n",
    "print(\"attn_weights shape:\", attn_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0da7da37-6c02-414b-9fdd-a3be4abdd9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = {\"is\", \"are\", \"the\", \"a\", \"an\", \"of\", \"to\", \"and\"}\n",
    "\n",
    "def filter_keywords(words):\n",
    "    return [w for w in words if w.lower() not in STOPWORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e04110f-9fec-48ef-9d42-651c49a8f2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transformers', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "keywords = extract_keywords_better(input_ids, attn_weights, top_k=4)\n",
    "# keywords = merge_subwords(keywords)\n",
    "keywords = filter_keywords(keywords)[:5]  # pick top 2 after filtering\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ec4886c-3330-44dd-a11c-ecdd51f28800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"averaged_perceptron_tagger_eng\")\n",
    "\n",
    "from nltk import pos_tag\n",
    "\n",
    "def prefer_nouns_adjectives(words):\n",
    "    tags = pos_tag(words, tagset=\"universal\")  # works in new NLTK\n",
    "    ranked = sorted(tags, key=lambda x: 0 if x[1] in (\"NOUN\",\"ADJ\") else 1)\n",
    "    return [w for w, t in ranked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f59ac170-4b4a-48aa-9585-700ba92c3aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_subwords(tokens):\n",
    "    merged = []\n",
    "    current = \"\"\n",
    "\n",
    "    for t in tokens:\n",
    "        if t.startswith(\"##\"):\n",
    "            current += t[2:]            # append subword\n",
    "        else:\n",
    "            if current:                # save previous word\n",
    "                merged.append(current)\n",
    "            current = t                # start a new word\n",
    "\n",
    "    if current:\n",
    "        merged.append(current)\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "661adda8-588e-45b0-975c-7c3498825877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transformers']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = extract_keywords_better(input_ids, attn_weights, top_k=2)\n",
    "keywords = merge_subwords(keywords)\n",
    "keywords = filter_keywords(keywords)\n",
    "keywords[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9adb212-fb1f-4d9d-b940-a9fa0346cee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "Self-supervised learning has become an important paradigm in natural language processing.\n",
      "    Models like BERT and RoBERTa achieve state-of-the-art performance by pre-training on large corpora.\n",
      "    Keyphrase extraction remains a challenging task in information retrieval.\n",
      "\n",
      "Predicted keyphrases:\n",
      "1. self - supervised learning has\n",
      "2. paradigm in natural language processing\n",
      "3. state -\n",
      "4. pre - training on large corp ora\n",
      "5. key\n",
      "6. ph\n",
      "7. rase extraction remains\n"
     ]
    }
   ],
   "source": [
    "import torch, os\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer\n",
    "import re\n",
    "from encoder_layer import Encoder_block\n",
    "from positional_encoding import Positional_Encoding\n",
    "\n",
    "# ----------------------------- CONFIG -----------------------------\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "seq_len = 256\n",
    "vocab_size = 30000\n",
    "num_classes = 3\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ------------------------- LOAD TOKENIZER -------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# -------------------------- BUILD MODEL --------------------------\n",
    "embedding_layer = nn.Embedding(vocab_size, d_model)\n",
    "pos_encoding = Positional_Encoding(seq_len, d_model)\n",
    "encoder = Encoder_block(d_model=d_model, d_ff=d_ff, num_heads=num_heads)\n",
    "classifier = nn.Linear(d_model, num_classes)   # B, I, O\n",
    "\n",
    "# Move everything to device\n",
    "embedding_layer.to(device)\n",
    "pos_encoding.to(device)\n",
    "encoder.to(device)\n",
    "classifier.to(device)\n",
    "\n",
    "# -------------------------- LOAD CHECKPOINT ----------------------\n",
    "# Change this to your best checkpoint\n",
    "CHECKPOINT_PATH = \"checkpoints/checkpoint_epoch_5.pt\"   # or whichever you prefer\n",
    "\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "\n",
    "# embedding_layer.load_state_dict(torch.load(\"checkpoints/embedding_layer.pt\") if os.path.exists(\"checkpoints/embedding_layer.pt\") \n",
    "#                                else print(\"Warning: No separate embedding checkpoint, assuming it was saved inside encoder\"))\n",
    "# If you only saved encoder + classifier (as in your training script), load like this:\n",
    "encoder.load_state_dict(checkpoint['model_state_dict'])\n",
    "classifier.load_state_dict(checkpoint['classifier_state_dict'])\n",
    "\n",
    "embedding_layer.eval()\n",
    "encoder.eval()\n",
    "classifier.eval()\n",
    "\n",
    "# -------------------------- ALIGNMENT HELPERS --------------------\n",
    "def align_tags_with_tokens(predicted_ids, word_ids):\n",
    "    \"\"\"\n",
    "    Convert subword-level predictions back to word-level BIO tags.\n",
    "    Rule: If any subword of a word is predicted as B or I → the whole word gets that tag.\n",
    "          Priority: B > I > O\n",
    "    \"\"\"\n",
    "    word_level_tags = []\n",
    "    current_word_id = None\n",
    "    current_best_tag = 0  # O\n",
    "\n",
    "    for word_id, pred_id in zip(word_ids, predicted_ids):\n",
    "        if word_id is None:\n",
    "            continue\n",
    "        if word_id != current_word_id:\n",
    "            if current_word_id is not None:\n",
    "                word_level_tags.append(current_best_tag)\n",
    "            current_word_id = word_id\n",
    "            current_best_tag = pred_id\n",
    "        else:\n",
    "            # Same word → keep the \"strongest\" tag (B > I > O)\n",
    "            if pred_id == 1:        # B has highest priority\n",
    "                current_best_tag = 1\n",
    "            elif pred_id == 2 and current_best_tag == 0:\n",
    "                current_best_tag = 2\n",
    "\n",
    "    # Don't forget the last word\n",
    "    if current_word_id is not None:\n",
    "        word_level_tags.append(current_best_tag)\n",
    "\n",
    "    return word_level_tags\n",
    "\n",
    "id2tag = {0: \"O\", 1: \"B\", 2: \"I\"}\n",
    "\n",
    "# -------------------------- PREDICTION FUNCTION ------------------\n",
    "def extract_keyphrases(text: str, top_k=None):\n",
    "    # 1. Tokenize with word_ids\n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        return_offsets_mapping=True,\n",
    "        return_special_tokens_mask=True\n",
    "    )\n",
    "    \n",
    "    input_ids = torch.tensor([encoded[\"input_ids\"]]).to(device)  # (1, seq_len)\n",
    "    attention_mask = torch.tensor([encoded[\"attention_mask\"]]).to(device)\n",
    "\n",
    "    # word_ids for alignment\n",
    "    word_ids = encoded.word_ids()\n",
    "\n",
    "    # 2. Forward pass\n",
    "    with torch.no_grad():\n",
    "        x = embedding_layer(input_ids)              # (1, seq, d_model)\n",
    "        x = pos_encoding(x)\n",
    "        encoder_out, _ = encoder(x, mask=None)      # (1, seq, d_model)\n",
    "        logits = classifier(encoder_out)            # (1, seq, 3)\n",
    "        \n",
    "        predictions = torch.argmax(logits, dim=-1)   # (1, seq)\n",
    "        predictions = predictions[0].cpu().tolist() # list of length seq\n",
    "\n",
    "    # 3. Align subword predictions → word-level\n",
    "    word_level_preds = align_tags_with_tokens(predictions, word_ids)\n",
    "\n",
    "    # 4. Extract phrases using offsets\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoded[\"input_ids\"])\n",
    "    offsets = encoded[\"offset_mapping\"]\n",
    "\n",
    "    keyphrases = []\n",
    "    current_phrase = []\n",
    "    current_start = None\n",
    "\n",
    "    for token, offset, pred in zip(tokens, offsets, predictions):\n",
    "        if encoded[\"special_tokens_mask\"][encoded[\"input_ids\"].index(tokenizer.convert_tokens_to_ids(token))]:\n",
    "            continue  # skip [CLS], [SEP], etc.\n",
    "\n",
    "        word_id = encoded.word_ids()[encoded[\"input_ids\"].index(tokenizer.convert_tokens_to_ids(token))]\n",
    "        if word_id is None:\n",
    "            continue\n",
    "\n",
    "        word_pred = word_level_preds[word_id]\n",
    "\n",
    "        if word_pred == 1:  # B\n",
    "            if current_phrase:\n",
    "                keyphrases.append(\" \".join(current_phrase))\n",
    "            current_phrase = [token.replace(\"##\", \"\")]\n",
    "            current_start = offset[0]\n",
    "        elif word_pred == 2 and current_phrase:  # I\n",
    "            current_phrase.append(token.replace(\"##\", \"\"))\n",
    "        else:  # O\n",
    "            if current_phrase:\n",
    "                keyphrases.append(\" \".join(current_phrase))\n",
    "                current_phrase = []\n",
    "\n",
    "    if current_phrase:\n",
    "        keyphrases.append(\" \".join(current_phrase))\n",
    "\n",
    "    # Optional: deduplication + lowercasing for cleaner output\n",
    "    keyphrases = list(dict.fromkeys(keyphrases))  # preserve order\n",
    "    keyphrases = [kp.strip() for kp in keyphrases if kp.strip()]\n",
    "\n",
    "    if top_k:\n",
    "        return keyphrases[:top_k]\n",
    "    return keyphrases\n",
    "\n",
    "# ----------------------------- USAGE EXAMPLE -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    sample_text = \"\"\"\n",
    "    Self-supervised learning has become an important paradigm in natural language processing.\n",
    "    Models like BERT and RoBERTa achieve state-of-the-art performance by pre-training on large corpora.\n",
    "    Keyphrase extraction remains a challenging task in information retrieval.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Input text:\")\n",
    "    print(sample_text.strip())\n",
    "    print(\"\\nPredicted keyphrases:\")\n",
    "    kps = extract_keyphrases(sample_text, top_k=10)\n",
    "    for i, kp in enumerate(kps, 1):\n",
    "        print(f\"{i}. {kp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "767282b1-823c-4ae0-9a84-9ab3f4c6792d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'projection_state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m projection \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m768\u001b[39m, \u001b[38;5;241m512\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m projection\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprojection_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      4\u001b[0m projection\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      5\u001b[0m projection\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[1;31mKeyError\u001b[0m: 'projection_state_dict'"
     ]
    }
   ],
   "source": [
    "projection = nn.Linear(768, 512)\n",
    "\n",
    "projection.load_state_dict(checkpoint['projection_state_dict'])\n",
    "projection.to(device)\n",
    "projection.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35efe419-cf0c-4331-a938-3d46030456b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transform', 'er', 'networks', 'have', 'ized', 'language', 'processing', 'with', 'attention', 'mechanisms', '.']\n"
     ]
    }
   ],
   "source": [
    "# predict_and_visualize.py\n",
    "\n",
    "from encoder_layer import Encoder_block\n",
    "from positional_encoding import Positional_Encoding\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "bert_emb = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").get_input_embeddings()\n",
    "\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "\n",
    "encoder = Encoder_block(d_model=d_model, num_heads=num_heads, d_ff=d_ff)\n",
    "classifier = nn.Linear(d_model, 3)\n",
    "\n",
    "checkpoint = torch.load(\"restored_model.pt\", map_location=\"cpu\")\n",
    "encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "classifier.load_state_dict(checkpoint['classifier_state_dict'])\n",
    "projection.load_state_dict(ckpt[\"projection_state_dict\"])\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "encoder.to(device)\n",
    "classifier.to(device)\n",
    "bert_emb.to(device)\n",
    "projection.to(device)\n",
    "\n",
    "encoder.eval()\n",
    "classifier.eval()\n",
    "\n",
    "def extract_keyphrases(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=256)\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x = bert_emb(input_ids)\n",
    "        x = projection(x)  \n",
    "        encoder_out, attn_weights = encoder(x, mask=inputs[\"attention_mask\"].to(device))\n",
    "        \n",
    "        # attn_weights will be list of (batch, heads, seq, seq) or whatever your function returns\n",
    "        logits = classifier(encoder_out)\n",
    "        preds = torch.argmax(logits, dim=-1)[0].cpu().numpy()\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "    phrases = []\n",
    "    curr = []\n",
    "    for tok, pred in zip(tokens, preds):\n",
    "        if tok in [\"[CLS]\", \"[SEP]\", \"[PAD]\"]: continue\n",
    "        tok = tok.replace(\"##\", \"\")\n",
    "        if pred == 1:  # B\n",
    "            if curr: phrases.append(\" \".join(curr))\n",
    "            curr = [tok]\n",
    "        elif pred == 2 and curr:\n",
    "            curr.append(tok)\n",
    "        else:\n",
    "            if curr: phrases.append(\" \".join(curr)); curr = []\n",
    "    if curr: phrases.append(\" \".join(curr))\n",
    "    return phrases\n",
    "\n",
    "# Test\n",
    "text = \"Transformer networks have revolutionized natural language processing with self-attention mechanisms.\"\n",
    "print(extract_keyphrases(text))\n",
    "# Output milega: ['transformer networks', 'natural language processing', 'self-attention mechanisms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "318695d9-fe71-41bf-8d03-4fd4c35e5c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'model_state_dict', 'classifier_state_dict', 'optimizer_state_dict', 'loss'])\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load(\"checkpoint_epoch_15.pt\", map_location=\"cpu\")\n",
    "print(ckpt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f323c16-67e8-4b5c-bb44-9bf7218591ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = nn.Linear(768, 512)\n",
    "encoder = Encoder_block(d_model=512, num_heads=8, d_ff=2048)\n",
    "classifier = nn.Linear(512, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f89fe04-149f-4fa6-865b-b66221bcb35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"checkpoint_epoch_15.pt\", map_location=\"cpu\")\n",
    "optimizer = torch.optim.AdamW(\n",
    "    list(projection.parameters()) +\n",
    "    list(encoder.parameters()) +\n",
    "    list(classifier.parameters()),\n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "optimizer.load_state_dict(ckpt[\"optimizer_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e282f342-6e91-4c60-8a32-9e97f5d3ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"projection_state_dict\": projection.state_dict(),\n",
    "    \"encoder_state_dict\": encoder.state_dict(),\n",
    "    \"classifier_state_dict\": classifier.state_dict()\n",
    "}, \"restored_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d604d6ae-c2cd-429a-93bf-63910fd2da35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(\"restored_model.pt\")\n",
    "projection.load_state_dict(ckpt[\"projection_state_dict\"])\n",
    "encoder.load_state_dict(ckpt[\"encoder_state_dict\"])\n",
    "classifier.load_state_dict(ckpt[\"classifier_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20de1998-35ae-46b5-9096-ea56aa840187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
